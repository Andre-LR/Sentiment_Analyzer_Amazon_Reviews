{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural Language Processing Python Project creating a Sentiment Analysis classifier using 3 different techniques:\n",
    "\n",
    "        K-nn (K-nearest neighbors)\n",
    "        VADER (Valence Aware Dictionary and sEntiment Reasoner)\n",
    "        Logistic Regression model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0. Read in Data and analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                     # pip install pandas\n",
    "import re                               # for regex\n",
    "import nltk                             # pip install nltk\n",
    "\n",
    "from nltk.corpus import stopwords                                       # pip install nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer             # Vader Sentiment Analysis (eng)\n",
    "from sklearn.feature_extraction.text import CountVectorizer             # pip install scikit-learn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "df = pd.read_csv('Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attribute information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first 5 data of the file\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of reviews\n",
    "print(df['Score'].value_counts().sort_index())\n",
    "\n",
    "# Data visualization\n",
    "graph = df['Score'].value_counts().sort_index().plot(kind='bar', title='Quantidade de avaliações em cada nota', figsize=(10, 5), color='red')\n",
    "graph.set_xlabel('Notas')\n",
    "graph.set_ylabel('Quantidade de avaliações')\n",
    "graph.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification of each review will be given according to the \"Score\".\n",
    "\n",
    "Neutral reviews will be ignored\n",
    "\n",
    "Score > 3: Positive\n",
    "\n",
    "Score < 3: Negative\n",
    "\n",
    "Score = 3: Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the neutral reviews\n",
    "df = df[df['Score'] != 3]\n",
    "\n",
    "# Cria nova coluna \"Sentimento\" e indica se os dados em positivos, negativos e neutros\n",
    "df['Sentiment'] = df['Score'].apply(lambda score: 'Positive' if score > 3 else ('Negative' if score < 3 else 'Neutral'))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopwords, HTML Tags, special characters and punctuation will be removed. The texts will be transformed into lowercase.\n",
    "\n",
    "Stopwords are words that don't bring meaning to our sentence, like \"I, are, all, mine, yours, ours, theirs, was...\".\n",
    "\n",
    "Normalization of similar words using \"stemming\". Stemming is the technique for removing suffixes and prefixes.\n",
    "\n",
    "        Ex: Watch, Watched, Watching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove HTML Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bought sever vital can dog food product found good qualiti product look like stew process meat smell better labrador finicki appreci product better'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_tags(text):\n",
    "    TAG_RE = re.compile(r'<[^>]+>')\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "df.Text = df.Text.apply(remove_tags)\n",
    "df.Text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove special characters (punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bought sever vital can dog food product found good qualiti product look like stew process meat smell better labrador finicki appreci product better'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_special_characters(text):\n",
    "    pattern = r'[^a-zA-z0-9\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "df.Text = df.Text.apply(remove_special_characters)\n",
    "df.Text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reviews to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bought sever vital can dog food product found good qualiti product look like stew process meat smell better labrador finicki appreci product better'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "df.Text = df.Text.apply(lower_case)\n",
    "df.Text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Andre_Rodrigues\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Andre_Rodrigues\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'bought sever vital dog food product found good qualiti product look like stew process meat smell better labrador finicki appreci product better'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "   \n",
    "    # Add specific words to the stop_words list if necessary\n",
    "    stop_words.update(['rt'])\n",
    "    \n",
    "    words = word_tokenize(text)\n",
    "    filtered_text = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    return filtered_text\n",
    "\n",
    "df.Text = df.Text.apply(remove_stopwords)\n",
    "\n",
    "# transform list to string\n",
    "df.Text = df.Text.apply(lambda x: ' '.join(x))\n",
    "df.Text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data normalization with 'stemming' technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bought sever vital dog food product found good qualiti product look like stew process meat smell better labrador finicki appreci product better'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stemming_words(text):\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    words = word_tokenize(text)\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return stemmed_words\n",
    "\n",
    "df.Text = df.Text.apply(stemming_words)\n",
    "\n",
    "# transform list to string\n",
    "df.Text = df.Text.apply(lambda x: ' '.join(x))\n",
    "df.Text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check frequent words in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can help us to insert new words into Stopwords list to be excluded from our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0)\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar as 20 palavras mais frequentes no dataset\n",
    "top_words = get_top_n_words(df.Text, n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printar as 20 palavras mais frequentes\n",
    "top_df = pd.DataFrame(top_words)\n",
    "top_df.columns=[\"Palavra\", \"Frequência\"]\n",
    "top_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Bag of Words, which consists of a set of words that exist in our Dataset. Each word will only appear 1x in the BOW.\n",
    "\n",
    "We will perform the tokenization of our dataset. Tokenization consists of transforming a string into a list of words called tokens. Tokens can consist of words, emoticons, hashtags, links, or even individual characters. A basic way to tokenize words is to split text based on whitespace and punctuation.\n",
    "\n",
    "The NLTK library provides a default tokenizer with the word_tokenize(text) method\n",
    "\n",
    "With the words tokenized, we will put a representation of each in our \"bag of words\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple BOW with 1 representation of each word\n",
    "def generate_bow(sentences):\n",
    "    words = CountVectorizer().fit(sentences)\n",
    "    # remove duplicates\n",
    "    words = list(set(words.get_feature_names()))\n",
    "    return words\n",
    "\n",
    "# Words and it's frequency BOW\n",
    "def generate_bow_freq(sentences):\n",
    "    vec = CountVectorizer().fit(sentences)\n",
    "    bag_of_words = vec.transform(sentences)\n",
    "    sum_words = bag_of_words.sum(axis=0)\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[0:]\n",
    "\n",
    "# Matrix BOW\n",
    "def generate_bow_matrix(sentences):\n",
    "    vec = CountVectorizer().fit(sentences)\n",
    "    bag_of_words = vec.transform(sentences)\n",
    "    return bag_of_words\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Balanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset that will be used to train the model must be balanced with the same amount of samples for pos and neg groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    3846\n",
       "Negative     759\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify how many positive and negative reviews we have\n",
    "df.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    759\n",
       "Negative    759\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 759 neg and 3846 pos\n",
    "# We take 759 samples of each feeling type to form the balanced dataset\n",
    "df_balanced = df.groupby('Sentiment').head(759)\n",
    "df_balanced.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes: x = (1214, 11), y = (1214,)\n",
      "Test shapes: x = (304, 11), y = (304,)\n"
     ]
    }
   ],
   "source": [
    "# Separate training and testing datasets\n",
    "df_train, df_test, label_column_train, label_column_test = train_test_split(df_balanced, df_balanced['Sentiment'], test_size=0.2, random_state=9)\n",
    "\n",
    "\n",
    "# must be the same size\n",
    "print(f\"Train shapes: x = {df_train.shape}, y = {label_column_train.shape}\")\n",
    "print(f\"Test shapes: x = {df_test.shape}, y = {label_column_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the models for classification below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-NN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN (K Nearest Neighbors) is a classification algorithm. KNN tries to predict the correct class for the test data by calculating the distance between the test data and all the training points. Then select the K number of points which is closet to the test data. The KNN algorithm calculates the probability of the test data belonging to the classes of ‘K’ training data and class holds the highest probability will be selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# K-nn sentiment analysis model\n",
    "def generate_knn_model(df, txt_vectorized_arr, k):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    # Parameters: Texts vectorized in 2D array, Array of Feelings\n",
    "    knn.fit(txt_vectorized_arr, df.Sentiment.values)\n",
    "\n",
    "    return knn\n",
    "\n",
    "# K-nn sentiment analysis of a single dataframe\n",
    "def knn_sentiment_analysis(df, txt_vectorized_arr, model):\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # predict\n",
    "    # Parameters: Texts vectorized in 2D array, Array of Feelings\n",
    "    df_copy['Knn_Predict'] = model.predict(txt_vectorized_arr)\n",
    "\n",
    "    # check accuracy\n",
    "    # Parameters: Array of Feelings, Array of Predicted Feelings\n",
    "    df_copy['Accuracy'] = accuracy_score(df_copy.Sentiment.values, df_copy.Knn_Predict.values)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "\n",
    "# Create the knn model\n",
    "# Parameters: Training dataframe, 2D array of vectorized DF texts, k-neighbors\n",
    "# cv.transform(df_train.Text).toarray() generates a 2D Array containing Vectorized of the texts from our DF so that it can be used to generate the model\n",
    "knn_model = generate_knn_model(df_train, cv.fit_transform(df_train.Text).toarray(), 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction using created model\n",
    "df_train_Knn = knn_sentiment_analysis(df_train, cv.transform(df_train.Text).toarray(), knn_model)\n",
    "df_test_Knn = knn_sentiment_analysis(df_test, cv.transform(df_test.Text).toarray(), knn_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison of the quantities obtained with the training x test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantity of positive and negative values in the dataset:\n",
      "Positive    619\n",
      "Negative    595\n",
      "Name: Sentiment, dtype: int64\n",
      "\n",
      "Quantity of positive and negative values found by the model:\n",
      "Positive    698\n",
      "Negative    516\n",
      "Name: Knn_Predict, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nQuantity of positive and negative values in the dataset:\")\n",
    "print(df_train_Knn.Sentiment.value_counts())\n",
    "\n",
    "print(\"\\nQuantity of positive and negative values found by the model:\")\n",
    "print(df_train_Knn.Knn_Predict.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Knn_Predict</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200</td>\n",
       "      <td>B0028C44Z0</td>\n",
       "      <td>A1WTXY4MW3YDF2</td>\n",
       "      <td>Gordon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1344729600</td>\n",
       "      <td>These mints are awesome!</td>\n",
       "      <td>huge suppli im still work plenti spare much ef...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.81631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>560</td>\n",
       "      <td>B000G6RYNE</td>\n",
       "      <td>A10RJEQN64ATXU</td>\n",
       "      <td>Paul Rodney Williams \"Higher Lifestyle\"</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1188777600</td>\n",
       "      <td>delicious</td>\n",
       "      <td>love kettl brand sea salt vinegar chip sinc fi...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.81631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>B001EO5QW8</td>\n",
       "      <td>AQLL2R1PPR46X</td>\n",
       "      <td>grumpyrainbow</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1192752000</td>\n",
       "      <td>good</td>\n",
       "      <td>good oatmeal like appl cinnamon best though wo...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.81631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>552</td>\n",
       "      <td>B000G6RYNE</td>\n",
       "      <td>A2B5OI74EHGVH1</td>\n",
       "      <td>Jane \"jdeaton2\"</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1273017600</td>\n",
       "      <td>dripping in oil</td>\n",
       "      <td>purcha low salt ind low salt howev mani mani c...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.81631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>2467</td>\n",
       "      <td>B002JX7GVM</td>\n",
       "      <td>AN9E7KAWWF95Q</td>\n",
       "      <td>ChristineThomson</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1348963200</td>\n",
       "      <td>Terrible flavor</td>\n",
       "      <td>almost gag first tast use coconut base product...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.81631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id   ProductId          UserId  \\\n",
       "199    200  B0028C44Z0  A1WTXY4MW3YDF2   \n",
       "559    560  B000G6RYNE  A10RJEQN64ATXU   \n",
       "46      47  B001EO5QW8   AQLL2R1PPR46X   \n",
       "551    552  B000G6RYNE  A2B5OI74EHGVH1   \n",
       "2466  2467  B002JX7GVM   AN9E7KAWWF95Q   \n",
       "\n",
       "                                  ProfileName  HelpfulnessNumerator  \\\n",
       "199                                    Gordon                     0   \n",
       "559   Paul Rodney Williams \"Higher Lifestyle\"                     3   \n",
       "46                              grumpyrainbow                     0   \n",
       "551                           Jane \"jdeaton2\"                     3   \n",
       "2466                         ChristineThomson                     0   \n",
       "\n",
       "      HelpfulnessDenominator  Score        Time                   Summary  \\\n",
       "199                        0      5  1344729600  These mints are awesome!   \n",
       "559                        3      5  1188777600                 delicious   \n",
       "46                         0      5  1192752000                      good   \n",
       "551                        8      1  1273017600           dripping in oil   \n",
       "2466                       0      2  1348963200           Terrible flavor   \n",
       "\n",
       "                                                   Text Sentiment Knn_Predict  \\\n",
       "199   huge suppli im still work plenti spare much ef...  Positive    Negative   \n",
       "559   love kettl brand sea salt vinegar chip sinc fi...  Positive    Positive   \n",
       "46    good oatmeal like appl cinnamon best though wo...  Positive    Positive   \n",
       "551   purcha low salt ind low salt howev mani mani c...  Negative    Negative   \n",
       "2466  almost gag first tast use coconut base product...  Negative    Negative   \n",
       "\n",
       "      Accuracy  \n",
       "199    0.81631  \n",
       "559    0.81631  \n",
       "46     0.81631  \n",
       "551    0.81631  \n",
       "2466   0.81631  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_Knn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tessting Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Knn_Predict</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>134</td>\n",
       "      <td>B003OB0IB8</td>\n",
       "      <td>AOTEC8KEH8JGN</td>\n",
       "      <td>Seth S Moyers</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1334880000</td>\n",
       "      <td>Great value and convenient ramen</td>\n",
       "      <td>got sale rough 25 cent per cup half price loca...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>278</td>\n",
       "      <td>B001D07IPG</td>\n",
       "      <td>A3QN14A5DGUA0U</td>\n",
       "      <td>J. Kraayenbrink</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1343692800</td>\n",
       "      <td>Excellent for G/F</td>\n",
       "      <td>plea ignor onestar comment check bag main ingr...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>1521</td>\n",
       "      <td>B001LQNX8S</td>\n",
       "      <td>A2QA5W84LGMG8L</td>\n",
       "      <td>Dee</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1342742400</td>\n",
       "      <td>These are absolutely revolting</td>\n",
       "      <td>flavor pod horrid order senseo stock long need...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>2952</td>\n",
       "      <td>B000H280KS</td>\n",
       "      <td>AJITVA02GIXPO</td>\n",
       "      <td>Gretchen</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1173312000</td>\n",
       "      <td>Looks better than it tasted, I'm told</td>\n",
       "      <td>sent gift found later mani item stale love tho...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>759</td>\n",
       "      <td>B0035YE9CS</td>\n",
       "      <td>AGXFRN1RZKI4J</td>\n",
       "      <td>Earl Hudson</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1321228800</td>\n",
       "      <td>Outstanding Product!</td>\n",
       "      <td>saw made interest processdecid give tri realli...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.6875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id   ProductId          UserId      ProfileName  HelpfulnessNumerator  \\\n",
       "133    134  B003OB0IB8   AOTEC8KEH8JGN    Seth S Moyers                     0   \n",
       "277    278  B001D07IPG  A3QN14A5DGUA0U  J. Kraayenbrink                     0   \n",
       "1520  1521  B001LQNX8S  A2QA5W84LGMG8L              Dee                     0   \n",
       "2951  2952  B000H280KS   AJITVA02GIXPO         Gretchen                     0   \n",
       "758    759  B0035YE9CS   AGXFRN1RZKI4J      Earl Hudson                     0   \n",
       "\n",
       "      HelpfulnessDenominator  Score        Time  \\\n",
       "133                        0      5  1334880000   \n",
       "277                        0      5  1343692800   \n",
       "1520                       0      1  1342742400   \n",
       "2951                       0      2  1173312000   \n",
       "758                        1      5  1321228800   \n",
       "\n",
       "                                    Summary  \\\n",
       "133        Great value and convenient ramen   \n",
       "277                       Excellent for G/F   \n",
       "1520         These are absolutely revolting   \n",
       "2951  Looks better than it tasted, I'm told   \n",
       "758                    Outstanding Product!   \n",
       "\n",
       "                                                   Text Sentiment Knn_Predict  \\\n",
       "133   got sale rough 25 cent per cup half price loca...  Positive    Negative   \n",
       "277   plea ignor onestar comment check bag main ingr...  Positive    Positive   \n",
       "1520  flavor pod horrid order senseo stock long need...  Negative    Positive   \n",
       "2951  sent gift found later mani item stale love tho...  Negative    Positive   \n",
       "758   saw made interest processdecid give tri realli...  Positive    Positive   \n",
       "\n",
       "      Accuracy  \n",
       "133     0.6875  \n",
       "277     0.6875  \n",
       "1520    0.6875  \n",
       "2951    0.6875  \n",
       "758     0.6875  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_Knn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vader model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valence Aware Dictionary and sEntiment Reasoner (VADER) is an open source Python library built for use in sentiment analysis tasks.\n",
    "\n",
    "Vader works in a very simple way: it has a collection of words, where each word already has a note (or feeling) assigned, and when passed a document (phrase) it returns the following values ​​in percentage:\n",
    "\n",
    "        pos: how positive is that sentence/document;\n",
    "\n",
    "        neu: how neutral is the sentence/document;\n",
    "\n",
    "        neg: how much is negative;\n",
    "\n",
    "compound: is the metric used to indicate the final conclusion regarding the sentence as a whole. It is calculated by adding the valence scores of each word in the lexicon, which generates a number between -1 (very negative) and +1 (very positive).\n",
    "\n",
    "        If compound >= 0.05 -> Positive\n",
    "\n",
    "        If compound <= -0.05 -> Negative\n",
    "\n",
    "        If compounding between -0.04 and 0.04 -> Neutral\n",
    "\n",
    "The compound is the most important metric when you just want to know if that sentence is positive or negative, because its value can be converted into those respective categories and that's exactly what we're going to learn to do here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Andre_Rodrigues\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Full analysis with pos, neg, neu and compound sentiment values\n",
    "# Returns a dictionary with the sentiment values neg, pos, neu and compound of the passed sentence\n",
    "def vader_complete_sentiment_analyse(text):\n",
    "    sentiment = SentimentIntensityAnalyzer().polarity_scores(text)\n",
    "    return sentiment\n",
    "\n",
    "# Simple analysis that returns pos, neg or neu according to the compound value\n",
    "def vader_get_sentiment(text):\n",
    "    sentiment = vader_complete_sentiment_analyse(text)\n",
    "    if sentiment['compound'] >= 0.05:\n",
    "        return 'Positive'\n",
    "    elif sentiment['compound'] <= -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Sentiment analysis of the dataset with the VADER model\n",
    "def vader_df_sentiment_analyse(df):\n",
    "    df_copy = df.copy()\n",
    "    df_copy['Vader_Predict'] = df_copy.Text.apply(vader_get_sentiment)\n",
    "    df_copy['Accuracy'] = accuracy_score(df_copy.Sentiment.values, df_copy.Vader_Predict.values)\n",
    "\n",
    "    return df_copy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_vader = vader_df_sentiment_analyse(df_train)\n",
    "df_test_vader = vader_df_sentiment_analyse(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison of the quantities obtained with the training x test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantity of actual positive and negative values in the dataset:\n",
      "Positive    619\n",
      "Negative    595\n",
      "Name: Sentiment, dtype: int64\n",
      "\n",
      "Quantity of positive and negative values found by the model:\n",
      "Positive    945\n",
      "Negative    191\n",
      "Neutral      78\n",
      "Name: Vader_Predict, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nQuantity of actual positive and negative values in the dataset:\")\n",
    "print(df_train_vader.Sentiment.value_counts())\n",
    "\n",
    "print(\"\\nQuantity of positive and negative values found by the model:\")\n",
    "print(df_train_vader.Vader_Predict.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Vader_Predict</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200</td>\n",
       "      <td>B0028C44Z0</td>\n",
       "      <td>A1WTXY4MW3YDF2</td>\n",
       "      <td>Gordon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1344729600</td>\n",
       "      <td>These mints are awesome!</td>\n",
       "      <td>huge suppli im still work plenti spare much ef...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.608731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>560</td>\n",
       "      <td>B000G6RYNE</td>\n",
       "      <td>A10RJEQN64ATXU</td>\n",
       "      <td>Paul Rodney Williams \"Higher Lifestyle\"</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1188777600</td>\n",
       "      <td>delicious</td>\n",
       "      <td>love kettl brand sea salt vinegar chip sinc fi...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.608731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>B001EO5QW8</td>\n",
       "      <td>AQLL2R1PPR46X</td>\n",
       "      <td>grumpyrainbow</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1192752000</td>\n",
       "      <td>good</td>\n",
       "      <td>good oatmeal like appl cinnamon best though wo...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.608731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>552</td>\n",
       "      <td>B000G6RYNE</td>\n",
       "      <td>A2B5OI74EHGVH1</td>\n",
       "      <td>Jane \"jdeaton2\"</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1273017600</td>\n",
       "      <td>dripping in oil</td>\n",
       "      <td>purcha low salt ind low salt howev mani mani c...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.608731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>2467</td>\n",
       "      <td>B002JX7GVM</td>\n",
       "      <td>AN9E7KAWWF95Q</td>\n",
       "      <td>ChristineThomson</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1348963200</td>\n",
       "      <td>Terrible flavor</td>\n",
       "      <td>almost gag first tast use coconut base product...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.608731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id   ProductId          UserId  \\\n",
       "199    200  B0028C44Z0  A1WTXY4MW3YDF2   \n",
       "559    560  B000G6RYNE  A10RJEQN64ATXU   \n",
       "46      47  B001EO5QW8   AQLL2R1PPR46X   \n",
       "551    552  B000G6RYNE  A2B5OI74EHGVH1   \n",
       "2466  2467  B002JX7GVM   AN9E7KAWWF95Q   \n",
       "\n",
       "                                  ProfileName  HelpfulnessNumerator  \\\n",
       "199                                    Gordon                     0   \n",
       "559   Paul Rodney Williams \"Higher Lifestyle\"                     3   \n",
       "46                              grumpyrainbow                     0   \n",
       "551                           Jane \"jdeaton2\"                     3   \n",
       "2466                         ChristineThomson                     0   \n",
       "\n",
       "      HelpfulnessDenominator  Score        Time                   Summary  \\\n",
       "199                        0      5  1344729600  These mints are awesome!   \n",
       "559                        3      5  1188777600                 delicious   \n",
       "46                         0      5  1192752000                      good   \n",
       "551                        8      1  1273017600           dripping in oil   \n",
       "2466                       0      2  1348963200           Terrible flavor   \n",
       "\n",
       "                                                   Text Sentiment  \\\n",
       "199   huge suppli im still work plenti spare much ef...  Positive   \n",
       "559   love kettl brand sea salt vinegar chip sinc fi...  Positive   \n",
       "46    good oatmeal like appl cinnamon best though wo...  Positive   \n",
       "551   purcha low salt ind low salt howev mani mani c...  Negative   \n",
       "2466  almost gag first tast use coconut base product...  Negative   \n",
       "\n",
       "     Vader_Predict  Accuracy  \n",
       "199       Positive  0.608731  \n",
       "559       Positive  0.608731  \n",
       "46        Positive  0.608731  \n",
       "551       Negative  0.608731  \n",
       "2466      Negative  0.608731  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_vader.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantity of actual positive and negative values in the dataset:\n",
      "Positive    619\n",
      "Negative    595\n",
      "Name: Sentiment, dtype: int64\n",
      "\n",
      "Quantity of positive and negative values found by the model:\n",
      "Positive    945\n",
      "Negative    191\n",
      "Neutral      78\n",
      "Name: Vader_Predict, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nQuantity of actual positive and negative values in the dataset:\")\n",
    "print(df_train_vader.Sentiment.value_counts())\n",
    "\n",
    "print(\"\\nQuantity of positive and negative values found by the model:\")\n",
    "print(df_train_vader.Vader_Predict.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Vader_Predict</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>134</td>\n",
       "      <td>B003OB0IB8</td>\n",
       "      <td>AOTEC8KEH8JGN</td>\n",
       "      <td>Seth S Moyers</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1334880000</td>\n",
       "      <td>Great value and convenient ramen</td>\n",
       "      <td>got sale rough 25 cent per cup half price loca...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.542763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>278</td>\n",
       "      <td>B001D07IPG</td>\n",
       "      <td>A3QN14A5DGUA0U</td>\n",
       "      <td>J. Kraayenbrink</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1343692800</td>\n",
       "      <td>Excellent for G/F</td>\n",
       "      <td>plea ignor onestar comment check bag main ingr...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.542763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>1521</td>\n",
       "      <td>B001LQNX8S</td>\n",
       "      <td>A2QA5W84LGMG8L</td>\n",
       "      <td>Dee</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1342742400</td>\n",
       "      <td>These are absolutely revolting</td>\n",
       "      <td>flavor pod horrid order senseo stock long need...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.542763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>2952</td>\n",
       "      <td>B000H280KS</td>\n",
       "      <td>AJITVA02GIXPO</td>\n",
       "      <td>Gretchen</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1173312000</td>\n",
       "      <td>Looks better than it tasted, I'm told</td>\n",
       "      <td>sent gift found later mani item stale love tho...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.542763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>759</td>\n",
       "      <td>B0035YE9CS</td>\n",
       "      <td>AGXFRN1RZKI4J</td>\n",
       "      <td>Earl Hudson</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1321228800</td>\n",
       "      <td>Outstanding Product!</td>\n",
       "      <td>saw made interest processdecid give tri realli...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.542763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id   ProductId          UserId      ProfileName  HelpfulnessNumerator  \\\n",
       "133    134  B003OB0IB8   AOTEC8KEH8JGN    Seth S Moyers                     0   \n",
       "277    278  B001D07IPG  A3QN14A5DGUA0U  J. Kraayenbrink                     0   \n",
       "1520  1521  B001LQNX8S  A2QA5W84LGMG8L              Dee                     0   \n",
       "2951  2952  B000H280KS   AJITVA02GIXPO         Gretchen                     0   \n",
       "758    759  B0035YE9CS   AGXFRN1RZKI4J      Earl Hudson                     0   \n",
       "\n",
       "      HelpfulnessDenominator  Score        Time  \\\n",
       "133                        0      5  1334880000   \n",
       "277                        0      5  1343692800   \n",
       "1520                       0      1  1342742400   \n",
       "2951                       0      2  1173312000   \n",
       "758                        1      5  1321228800   \n",
       "\n",
       "                                    Summary  \\\n",
       "133        Great value and convenient ramen   \n",
       "277                       Excellent for G/F   \n",
       "1520         These are absolutely revolting   \n",
       "2951  Looks better than it tasted, I'm told   \n",
       "758                    Outstanding Product!   \n",
       "\n",
       "                                                   Text Sentiment  \\\n",
       "133   got sale rough 25 cent per cup half price loca...  Positive   \n",
       "277   plea ignor onestar comment check bag main ingr...  Positive   \n",
       "1520  flavor pod horrid order senseo stock long need...  Negative   \n",
       "2951  sent gift found later mani item stale love tho...  Negative   \n",
       "758   saw made interest processdecid give tri realli...  Positive   \n",
       "\n",
       "     Vader_Predict  Accuracy  \n",
       "133       Positive  0.542763  \n",
       "277       Positive  0.542763  \n",
       "1520      Negative  0.542763  \n",
       "2951      Positive  0.542763  \n",
       "758       Positive  0.542763  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_vader.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a probabilistic prediction model that seeks to predict a binary value of 0 or 1, which is more malleable and can be used in complex classification cases. In the formula of this method, outliers are not considered, since they are only considered data close to a line that divides the data according to the specified attributes. Like the Perceptron algorithm, it is an algorithm that requires a lot of training and can only find a linear separator for the data if the data are linearly separable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def logistic_regression_sentiment_analysis(df, iteractions=1000):\n",
    "    # generate BOW matrix\n",
    "    bow_matrix = generate_bow_matrix(df.Text)\n",
    "    # generate BOW frequency\n",
    "    bow_freq = generate_bow_freq(df.Text)\n",
    "    # generate BOW frequency dataframe\n",
    "    bow_freq_df = pd.DataFrame(bow_freq)\n",
    "    bow_freq_df.columns=[\"Palavra\", \"Frequência\"]\n",
    "    \n",
    "    # Logistic Regression\n",
    "    lr= LogisticRegression(max_iter=iteractions)\n",
    "    lr.fit(bow_matrix, df.Sentiment)\n",
    "\n",
    "    df_copy = df.copy()\n",
    "    # predict\n",
    "    df_copy['Logistic_Predict'] = lr.predict(bow_matrix)\n",
    "    # check accuracy\n",
    "    df_copy['Accuracy'] = accuracy_score(df_copy.Sentiment.values, df_copy.Logistic_Predict.values)\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_lr = logistic_regression_sentiment_analysis(df_train)\n",
    "df_test_lr = logistic_regression_sentiment_analysis(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison of the quantities obtained with the training x test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantidade de valores positivos e negativos reais no dataset:\n",
      "Positive    619\n",
      "Negative    595\n",
      "Name: Sentiment, dtype: int64\n",
      "\n",
      "Quantidade de valores positivos e negativos encontrados pelo modelo:\n",
      "Positive    623\n",
      "Negative    591\n",
      "Name: Logistic_Predict, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nQuantidade de valores positivos e negativos reais no dataset:\")\n",
    "print(df_train_lr.Sentiment.value_counts())\n",
    "\n",
    "print(\"\\nQuantidade de valores positivos e negativos encontrados pelo modelo:\")\n",
    "print(df_train_lr.Logistic_Predict.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Vader_Predict</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200</td>\n",
       "      <td>B0028C44Z0</td>\n",
       "      <td>A1WTXY4MW3YDF2</td>\n",
       "      <td>Gordon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1344729600</td>\n",
       "      <td>These mints are awesome!</td>\n",
       "      <td>huge suppli im still work plenti spare much ef...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.608731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>560</td>\n",
       "      <td>B000G6RYNE</td>\n",
       "      <td>A10RJEQN64ATXU</td>\n",
       "      <td>Paul Rodney Williams \"Higher Lifestyle\"</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1188777600</td>\n",
       "      <td>delicious</td>\n",
       "      <td>love kettl brand sea salt vinegar chip sinc fi...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.608731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>B001EO5QW8</td>\n",
       "      <td>AQLL2R1PPR46X</td>\n",
       "      <td>grumpyrainbow</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1192752000</td>\n",
       "      <td>good</td>\n",
       "      <td>good oatmeal like appl cinnamon best though wo...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.608731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>552</td>\n",
       "      <td>B000G6RYNE</td>\n",
       "      <td>A2B5OI74EHGVH1</td>\n",
       "      <td>Jane \"jdeaton2\"</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1273017600</td>\n",
       "      <td>dripping in oil</td>\n",
       "      <td>purcha low salt ind low salt howev mani mani c...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.608731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>2467</td>\n",
       "      <td>B002JX7GVM</td>\n",
       "      <td>AN9E7KAWWF95Q</td>\n",
       "      <td>ChristineThomson</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1348963200</td>\n",
       "      <td>Terrible flavor</td>\n",
       "      <td>almost gag first tast use coconut base product...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.608731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id   ProductId          UserId  \\\n",
       "199    200  B0028C44Z0  A1WTXY4MW3YDF2   \n",
       "559    560  B000G6RYNE  A10RJEQN64ATXU   \n",
       "46      47  B001EO5QW8   AQLL2R1PPR46X   \n",
       "551    552  B000G6RYNE  A2B5OI74EHGVH1   \n",
       "2466  2467  B002JX7GVM   AN9E7KAWWF95Q   \n",
       "\n",
       "                                  ProfileName  HelpfulnessNumerator  \\\n",
       "199                                    Gordon                     0   \n",
       "559   Paul Rodney Williams \"Higher Lifestyle\"                     3   \n",
       "46                              grumpyrainbow                     0   \n",
       "551                           Jane \"jdeaton2\"                     3   \n",
       "2466                         ChristineThomson                     0   \n",
       "\n",
       "      HelpfulnessDenominator  Score        Time                   Summary  \\\n",
       "199                        0      5  1344729600  These mints are awesome!   \n",
       "559                        3      5  1188777600                 delicious   \n",
       "46                         0      5  1192752000                      good   \n",
       "551                        8      1  1273017600           dripping in oil   \n",
       "2466                       0      2  1348963200           Terrible flavor   \n",
       "\n",
       "                                                   Text Sentiment  \\\n",
       "199   huge suppli im still work plenti spare much ef...  Positive   \n",
       "559   love kettl brand sea salt vinegar chip sinc fi...  Positive   \n",
       "46    good oatmeal like appl cinnamon best though wo...  Positive   \n",
       "551   purcha low salt ind low salt howev mani mani c...  Negative   \n",
       "2466  almost gag first tast use coconut base product...  Negative   \n",
       "\n",
       "     Vader_Predict  Accuracy  \n",
       "199       Positive  0.608731  \n",
       "559       Positive  0.608731  \n",
       "46        Positive  0.608731  \n",
       "551       Negative  0.608731  \n",
       "2466      Negative  0.608731  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_vader.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Logistic_Predict</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>134</td>\n",
       "      <td>B003OB0IB8</td>\n",
       "      <td>AOTEC8KEH8JGN</td>\n",
       "      <td>Seth S Moyers</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1334880000</td>\n",
       "      <td>Great value and convenient ramen</td>\n",
       "      <td>got sale rough 25 cent per cup half price loca...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>278</td>\n",
       "      <td>B001D07IPG</td>\n",
       "      <td>A3QN14A5DGUA0U</td>\n",
       "      <td>J. Kraayenbrink</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1343692800</td>\n",
       "      <td>Excellent for G/F</td>\n",
       "      <td>plea ignor onestar comment check bag main ingr...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>1521</td>\n",
       "      <td>B001LQNX8S</td>\n",
       "      <td>A2QA5W84LGMG8L</td>\n",
       "      <td>Dee</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1342742400</td>\n",
       "      <td>These are absolutely revolting</td>\n",
       "      <td>flavor pod horrid order senseo stock long need...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>2952</td>\n",
       "      <td>B000H280KS</td>\n",
       "      <td>AJITVA02GIXPO</td>\n",
       "      <td>Gretchen</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1173312000</td>\n",
       "      <td>Looks better than it tasted, I'm told</td>\n",
       "      <td>sent gift found later mani item stale love tho...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>759</td>\n",
       "      <td>B0035YE9CS</td>\n",
       "      <td>AGXFRN1RZKI4J</td>\n",
       "      <td>Earl Hudson</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1321228800</td>\n",
       "      <td>Outstanding Product!</td>\n",
       "      <td>saw made interest processdecid give tri realli...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id   ProductId          UserId      ProfileName  HelpfulnessNumerator  \\\n",
       "133    134  B003OB0IB8   AOTEC8KEH8JGN    Seth S Moyers                     0   \n",
       "277    278  B001D07IPG  A3QN14A5DGUA0U  J. Kraayenbrink                     0   \n",
       "1520  1521  B001LQNX8S  A2QA5W84LGMG8L              Dee                     0   \n",
       "2951  2952  B000H280KS   AJITVA02GIXPO         Gretchen                     0   \n",
       "758    759  B0035YE9CS   AGXFRN1RZKI4J      Earl Hudson                     0   \n",
       "\n",
       "      HelpfulnessDenominator  Score        Time  \\\n",
       "133                        0      5  1334880000   \n",
       "277                        0      5  1343692800   \n",
       "1520                       0      1  1342742400   \n",
       "2951                       0      2  1173312000   \n",
       "758                        1      5  1321228800   \n",
       "\n",
       "                                    Summary  \\\n",
       "133        Great value and convenient ramen   \n",
       "277                       Excellent for G/F   \n",
       "1520         These are absolutely revolting   \n",
       "2951  Looks better than it tasted, I'm told   \n",
       "758                    Outstanding Product!   \n",
       "\n",
       "                                                   Text Sentiment  \\\n",
       "133   got sale rough 25 cent per cup half price loca...  Positive   \n",
       "277   plea ignor onestar comment check bag main ingr...  Positive   \n",
       "1520  flavor pod horrid order senseo stock long need...  Negative   \n",
       "2951  sent gift found later mani item stale love tho...  Negative   \n",
       "758   saw made interest processdecid give tri realli...  Positive   \n",
       "\n",
       "     Logistic_Predict  Accuracy  \n",
       "133          Positive       1.0  \n",
       "277          Positive       1.0  \n",
       "1520         Negative       1.0  \n",
       "2951         Negative       1.0  \n",
       "758          Positive       1.0  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_lr.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "507b3d2bd6a2fcaac61041e0b692894325b154ca042b34fb821ed65ea08d8bdd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
