{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                     # pip install pandas\n",
    "import re                               # for regex\n",
    "import nltk                             # pip install nltk\n",
    "\n",
    "from nltk.corpus import stopwords                                       # pip install nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer             # Vader Sentiment Analysis (eng)\n",
    "from sklearn.feature_extraction.text import CountVectorizer             # pip install scikit-learn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informação dos atributos\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar os 5 primeiros dados do arquivo\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visão geral sobre as avaliações\n",
    "print(df['Score'].value_counts().sort_index())\n",
    "\n",
    "# Visualização dos dados\n",
    "graph = df['Score'].value_counts().sort_index().plot(kind='bar', title='Quantidade de avaliações em cada nota', figsize=(10, 5), color='red')\n",
    "graph.set_xlabel('Notas')\n",
    "graph.set_ylabel('Quantidade de avaliações')\n",
    "graph.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificar os tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classificação levará em conta a nota \"Score\" que cada um levou na avaliação.\n",
    "Neutros não serão considerados para o treinamento do modelo.\n",
    "\n",
    "Score > 3: Positivo\n",
    "\n",
    "Score < 3: Negativo\n",
    "\n",
    "Score = 3: Neutro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove os neutros\n",
    "df = df[df['Score'] != 3]\n",
    "\n",
    "# Cria nova coluna \"Sentimento\" e indica se os dados em positivos, negativos e neutros\n",
    "df['Sentiment'] = df['Score'].apply(lambda score: 'Positive' if score > 3 else ('Negative' if score < 3 else 'Neutral'))\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpeza dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizando remoção de: Tags HTML, caracteres especiais, colocando todas as letras em minúsculo...\n",
    "\n",
    "Remoção de Stopwords. Stopwords são paavras que não trazem significado para nossa frase, como \"eu, estão, tudo, meu, seu, nosso, deles, estava...\". Foram incluidas palavras \"like\", \"good\" e \"great\", pois estavam sendo usadas tanto nas sentenças \"negativas\" quanto nas positivas, provavelmente com o sentido do produto estar \"not good\".\n",
    "\n",
    "Normalização de palavras semelhantes/variações usando \"stemming\". Stemming é a técnica para remoção de sufixos e prefixos de uma palavra. Ex: Watch, Watched, Watching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remover Tags HTML com Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(text):\n",
    "    TAG_RE = re.compile(r'<[^>]+>')\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "# Remover Tags de todos os 'Reviews'\n",
    "df.Text = df.Text.apply(remove_tags)\n",
    "df.Text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remover caracteres especiais (pontuação)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "    # Padrão a ser mantido\n",
    "    pattern = r'[^a-zA-z0-9\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "# Remover caracteres especiais de todos os 'Reviews'\n",
    "df.Text = df.Text.apply(remove_special_characters)\n",
    "df.Text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Colocar todas as letras em minúsculo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "# Colocar todas as letras em minúsculo de todos os 'Reviews'\n",
    "df.Text = df.Text.apply(lower_case)\n",
    "df.Text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remover palavras 'irrelevantes' (stopwords)\n",
    "Tempo médio de execução: 1min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Andre_Rodrigues\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Andre_Rodrigues\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "   \n",
    "    # Adicionar palavras específicas que podem não conter na biblioteca\n",
    "    stop_words.update(['rt'])\n",
    "    \n",
    "    words = word_tokenize(text)\n",
    "    filtered_text = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    return filtered_text\n",
    "\n",
    "# Remover palavras 'irrelevantes'\n",
    "df.Text = df.Text.apply(remove_stopwords)\n",
    "\n",
    "# transform list to string\n",
    "df.Text = df.Text.apply(lambda x: ' '.join(x))\n",
    "df.Text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalização das palavras usando a técnica de 'stemming'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bought sever vital can dog food product found good qualiti product look like stew process meat smell better labrador finicki appreci product better'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stemming_words(text):\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    words = word_tokenize(text)\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return stemmed_words\n",
    "\n",
    "# Normalização das palavras\n",
    "df.Text = df.Text.apply(stemming_words)\n",
    "\n",
    "# transform list to string\n",
    "df.Text = df.Text.apply(lambda x: ' '.join(x))\n",
    "df.Text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verificar as palavras mais frequentes no dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\"n\" corresponde às top \"n\" palavras mais frequentes no dataset.\n",
    "\n",
    "Esta atividade pode nos ajudar a voltar a lista de StopWords e inserir novas palavras para serem excluidas de nossa análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0)\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar as 20 palavras mais frequentes no dataset\n",
    "top_words = get_top_n_words(df.Text, n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printar as 20 palavras mais frequentes\n",
    "top_df = pd.DataFrame(top_words)\n",
    "top_df.columns=[\"Palavra\", \"Frequência\"]\n",
    "top_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando \"bag of words\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criaremos agora nossa Bag of Words, que consiste em um conjunto de palavras que existem no nosso Dataset. Cada palavra aparecerá apenas 1x na nossa BOW.\n",
    "\n",
    "Para isso, iremos realizar a tokenização do nosso dataset. Tokenização consiste em tranformar uma string em uma lista de palavras chamadas tokens. Os tokens podem consistir em palavras, emoticons, hashtags, links ou até mesmo caracteres individuais. Uma maneira básica de dividir as palavras em tokens é dividir o texto com base no espaço em branco e na pontuação.\n",
    "\n",
    "A biblioteca NLTK fornece um tokenizador padrão com o método word_tokenize(texto)\n",
    "\n",
    "Com as palavras tokenizadas, iremos colocar uma representação de cada na nossa \"bag of words\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOW simples com 1 amostra de cada palavra\n",
    "def generate_bow(sentences):\n",
    "    # Tokenização/Vetor das palavras\n",
    "    words = CountVectorizer().fit(sentences)\n",
    "    # remove duplicates\n",
    "    words = list(set(words.get_feature_names()))\n",
    "    return words\n",
    "\n",
    "# BOW com palavra e frequência\n",
    "def generate_bow_freq(sentences):\n",
    "    vec = CountVectorizer().fit(sentences)\n",
    "    bag_of_words = vec.transform(sentences)\n",
    "    sum_words = bag_of_words.sum(axis=0)\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[0:]\n",
    "\n",
    "# BOW matrix\n",
    "def generate_bow_matrix(sentences):\n",
    "    vec = CountVectorizer().fit(sentences)\n",
    "    bag_of_words = vec.transform(sentences)\n",
    "    return bag_of_words\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação do Dataset balanceado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosso dataset que será usado para treinar o modelo deverá estar balanceado, ou seja, mesma quantidade de amostras para os 2 grupos de \"sentimento\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    3846\n",
       "Negative     759\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify how many positive and negative reviews we have\n",
    "df.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    759\n",
       "Negative    759\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Temos 759 negativos e 3846 positivos\n",
    "# Pegamos 759 amostas de cada tipo de sentimento para formar o Dataset de treino (amostras balanceadas)\n",
    "df_balanced = df.groupby('Sentiment').head(759)\n",
    "df_balanced.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>bought sever vital can dog food product found ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>product arriv label jumbo salt peanutsth peanu...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>confect around centuri light pillowi citrus ge...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>look secret ingredi robitussin believ found go...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>great taffi great price wide assort yummi taff...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \\\n",
       "0  Good Quality Dog Food  bought sever vital can dog food product found ...   \n",
       "1      Not as Advertised  product arriv label jumbo salt peanutsth peanu...   \n",
       "2  \"Delight\" says it all  confect around centuri light pillowi citrus ge...   \n",
       "3         Cough Medicine  look secret ingredi robitussin believ found go...   \n",
       "4            Great taffy  great taffi great price wide assort yummi taff...   \n",
       "\n",
       "  Sentiment  \n",
       "0  Positive  \n",
       "1  Negative  \n",
       "2  Positive  \n",
       "3  Negative  \n",
       "4  Positive  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando dataset de treino, validação e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes: x = (1214, 11), y = (1214,)\n",
      "Test shapes: x = (304, 11), y = (304,)\n"
     ]
    }
   ],
   "source": [
    "# Separando os conjuntos de dados de treino e teste\n",
    "df_train, df_test, label_column_train, label_column_test = train_test_split(df_balanced, df_balanced['Sentiment'], test_size=0.2, random_state=9)\n",
    "\n",
    "# print tamanho dos conjuntos de dados\n",
    "# os conjuntos devem ter o mesmo tamanho\n",
    "print(f\"Train shapes: x = {df_train.shape}, y = {label_column_train.shape}\")\n",
    "print(f\"Test shapes: x = {df_test.shape}, y = {label_column_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constuindo modelos de classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada modelo receberá o texto como \"input\" e retornará se é positivo ou negativo\n",
    "\n",
    "Utilizaremos os modelos para classificação abaixo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-NN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O KNN (K Nearest Neighbors) é um algoritmo de classificação baseado na ideia de que dados de uma mesma classe estariam próximos entre si no espaço. Para esse cálculo de proximidade, é calculada a distância de um dado não classificado em relação a todos os dados históricos que já possuem classificação. A partir disso, são selecionados os K vizinhos mais próximos do novo dado para determinar a classificação dele via votação. O tipo de classificação que tiver mais vizinhos representantes irá corresponder a classe do novo dado. Esta variável K é a variável mais importante deste algoritmo, e pode ser configurada na variável **K** da função *knn_sentiment_analysis* criada.\n",
    "\n",
    "Este é um algoritmo não paramétrico que é conhecido por ser lazy, isto é, não necessitar da realização de computação durante o treinamento (apenas exigindo memorização dos dados de treinamento), o que facilita o processo inicial. Por outro lado, isso torna a etapa de predição muito mais custosa e lenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# K-nn sentiment analysis model\n",
    "def generate_knn_model(df, txt_vectorized_arr, k):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    # Parametros: Textos vetorizados no array 2D, Array de Sentimentos\n",
    "    knn.fit(txt_vectorized_arr, df.Sentiment.values)\n",
    "\n",
    "    return knn\n",
    "\n",
    "# K-nn sentiment analysis of a single dataframe\n",
    "def knn_sentiment_analysis(df, txt_vectorized_arr, model):\n",
    "    # cria copia do dataframe para não alterar o original\n",
    "    df_copy = df.copy()\n",
    "    # predict\n",
    "    # Parameters: Textos vetorizados no array 2D\n",
    "    df_copy['Knn_Predict'] = model.predict(txt_vectorized_arr)\n",
    "\n",
    "    # check accuracy\n",
    "    # Parameters: Array de Sentimentos, Array de Sentimentos previstos\n",
    "    df_copy['Accuracy'] = accuracy_score(df_copy.Sentiment.values, df_copy.Knn_Predict.values)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "\n",
    "# Cria o modelo knn\n",
    "# Parameters: Dataframe de treino, Array 2D dos textos do DF vetorizados, k-neighbors\n",
    "# cv.transform(df_train.Text).toarray() gera um Array 2D contendo Vectorized dos textos do nosso DF para que possa ser usado para gerar o modelo\n",
    "knn_model = generate_knn_model(df_train, cv.fit_transform(df_train.Text).toarray(), 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faz a predição do treino com o modelo criado\n",
    "df_train_Knn = knn_sentiment_analysis(df_train, cv.transform(df_train.Text).toarray(), knn_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_Knn = knn_sentiment_analysis(df_test, cv.transform(df_test.Text).toarray(), knn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Resultado Treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparação das quantidades obtidas com o dataset de treino x teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantidade de valores positivos e negativos reais no dataset:\n",
      "Positive    619\n",
      "Negative    595\n",
      "Name: Sentiment, dtype: int64\n",
      "\n",
      "Quantidade de valores positivos e negativos encontrados pelo modelo:\n",
      "Positive    690\n",
      "Negative    524\n",
      "Name: Knn_Predict, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Train - Visão geral sobre os sentimentos\n",
    "print(\"\\nQuantidade de valores positivos e negativos reais no dataset:\")\n",
    "print(df_train_Knn.Sentiment.value_counts())\n",
    "\n",
    "print(\"\\nQuantidade de valores positivos e negativos encontrados pelo modelo:\")\n",
    "print(df_train_Knn.Knn_Predict.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Knn_Predict</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200</td>\n",
       "      <td>B0028C44Z0</td>\n",
       "      <td>A1WTXY4MW3YDF2</td>\n",
       "      <td>Gordon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1344729600</td>\n",
       "      <td>These mints are awesome!</td>\n",
       "      <td>huge suppli im still work plenti spare much ef...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.817957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>560</td>\n",
       "      <td>B000G6RYNE</td>\n",
       "      <td>A10RJEQN64ATXU</td>\n",
       "      <td>Paul Rodney Williams \"Higher Lifestyle\"</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1188777600</td>\n",
       "      <td>delicious</td>\n",
       "      <td>love kettl brand sea salt vinegar chip sinc fi...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.817957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>B001EO5QW8</td>\n",
       "      <td>AQLL2R1PPR46X</td>\n",
       "      <td>grumpyrainbow</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1192752000</td>\n",
       "      <td>good</td>\n",
       "      <td>good oatmeal like appl cinnamon best though wo...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.817957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>552</td>\n",
       "      <td>B000G6RYNE</td>\n",
       "      <td>A2B5OI74EHGVH1</td>\n",
       "      <td>Jane \"jdeaton2\"</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1273017600</td>\n",
       "      <td>dripping in oil</td>\n",
       "      <td>purchas low salt inde low salt howev mani mani...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.817957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>2467</td>\n",
       "      <td>B002JX7GVM</td>\n",
       "      <td>AN9E7KAWWF95Q</td>\n",
       "      <td>ChristineThomson</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1348963200</td>\n",
       "      <td>Terrible flavor</td>\n",
       "      <td>almost gag first tast use coconut base product...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.817957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id   ProductId          UserId  \\\n",
       "199    200  B0028C44Z0  A1WTXY4MW3YDF2   \n",
       "559    560  B000G6RYNE  A10RJEQN64ATXU   \n",
       "46      47  B001EO5QW8   AQLL2R1PPR46X   \n",
       "551    552  B000G6RYNE  A2B5OI74EHGVH1   \n",
       "2466  2467  B002JX7GVM   AN9E7KAWWF95Q   \n",
       "\n",
       "                                  ProfileName  HelpfulnessNumerator  \\\n",
       "199                                    Gordon                     0   \n",
       "559   Paul Rodney Williams \"Higher Lifestyle\"                     3   \n",
       "46                              grumpyrainbow                     0   \n",
       "551                           Jane \"jdeaton2\"                     3   \n",
       "2466                         ChristineThomson                     0   \n",
       "\n",
       "      HelpfulnessDenominator  Score        Time                   Summary  \\\n",
       "199                        0      5  1344729600  These mints are awesome!   \n",
       "559                        3      5  1188777600                 delicious   \n",
       "46                         0      5  1192752000                      good   \n",
       "551                        8      1  1273017600           dripping in oil   \n",
       "2466                       0      2  1348963200           Terrible flavor   \n",
       "\n",
       "                                                   Text Sentiment Knn_Predict  \\\n",
       "199   huge suppli im still work plenti spare much ef...  Positive    Negative   \n",
       "559   love kettl brand sea salt vinegar chip sinc fi...  Positive    Positive   \n",
       "46    good oatmeal like appl cinnamon best though wo...  Positive    Positive   \n",
       "551   purchas low salt inde low salt howev mani mani...  Negative    Negative   \n",
       "2466  almost gag first tast use coconut base product...  Negative    Negative   \n",
       "\n",
       "      Accuracy  \n",
       "199   0.817957  \n",
       "559   0.817957  \n",
       "46    0.817957  \n",
       "551   0.817957  \n",
       "2466  0.817957  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show dataframe\n",
    "df_train_Knn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Knn_Predict</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>134</td>\n",
       "      <td>B003OB0IB8</td>\n",
       "      <td>AOTEC8KEH8JGN</td>\n",
       "      <td>Seth S Moyers</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1334880000</td>\n",
       "      <td>Great value and convenient ramen</td>\n",
       "      <td>got sale rough 25 cent per cup half price loca...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>278</td>\n",
       "      <td>B001D07IPG</td>\n",
       "      <td>A3QN14A5DGUA0U</td>\n",
       "      <td>J. Kraayenbrink</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1343692800</td>\n",
       "      <td>Excellent for G/F</td>\n",
       "      <td>pleas ignor onestar comment check bag main ing...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>1521</td>\n",
       "      <td>B001LQNX8S</td>\n",
       "      <td>A2QA5W84LGMG8L</td>\n",
       "      <td>Dee</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1342742400</td>\n",
       "      <td>These are absolutely revolting</td>\n",
       "      <td>flavor pod horrid order senseo stock long need...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>2952</td>\n",
       "      <td>B000H280KS</td>\n",
       "      <td>AJITVA02GIXPO</td>\n",
       "      <td>Gretchen</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1173312000</td>\n",
       "      <td>Looks better than it tasted, I'm told</td>\n",
       "      <td>sent gift found later mani item stale love tho...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>759</td>\n",
       "      <td>B0035YE9CS</td>\n",
       "      <td>AGXFRN1RZKI4J</td>\n",
       "      <td>Earl Hudson</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1321228800</td>\n",
       "      <td>Outstanding Product!</td>\n",
       "      <td>saw made interest processdecid give tri realli...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id   ProductId          UserId      ProfileName  HelpfulnessNumerator  \\\n",
       "133    134  B003OB0IB8   AOTEC8KEH8JGN    Seth S Moyers                     0   \n",
       "277    278  B001D07IPG  A3QN14A5DGUA0U  J. Kraayenbrink                     0   \n",
       "1520  1521  B001LQNX8S  A2QA5W84LGMG8L              Dee                     0   \n",
       "2951  2952  B000H280KS   AJITVA02GIXPO         Gretchen                     0   \n",
       "758    759  B0035YE9CS   AGXFRN1RZKI4J      Earl Hudson                     0   \n",
       "\n",
       "      HelpfulnessDenominator  Score        Time  \\\n",
       "133                        0      5  1334880000   \n",
       "277                        0      5  1343692800   \n",
       "1520                       0      1  1342742400   \n",
       "2951                       0      2  1173312000   \n",
       "758                        1      5  1321228800   \n",
       "\n",
       "                                    Summary  \\\n",
       "133        Great value and convenient ramen   \n",
       "277                       Excellent for G/F   \n",
       "1520         These are absolutely revolting   \n",
       "2951  Looks better than it tasted, I'm told   \n",
       "758                    Outstanding Product!   \n",
       "\n",
       "                                                   Text Sentiment Knn_Predict  \\\n",
       "133   got sale rough 25 cent per cup half price loca...  Positive    Negative   \n",
       "277   pleas ignor onestar comment check bag main ing...  Positive    Positive   \n",
       "1520  flavor pod horrid order senseo stock long need...  Negative    Positive   \n",
       "2951  sent gift found later mani item stale love tho...  Negative    Positive   \n",
       "758   saw made interest processdecid give tri realli...  Positive    Negative   \n",
       "\n",
       "      Accuracy  \n",
       "133   0.684211  \n",
       "277   0.684211  \n",
       "1520  0.684211  \n",
       "2951  0.684211  \n",
       "758   0.684211  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_Knn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vader model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valence Aware Dictionary and sEntiment Reasoner (VADER) é uma biblioteca do Python de código aberto construída para ser usada em tarefas de análise de sentimentos.\n",
    "\n",
    "A vader funciona de maneira bem simples: ela tem uma coleção de palavras, onde cada palavra já possuí uma nota(ou sentimento) atribuida, e quando passado um documento (frase) retorna os seguintes valores em porcentagem:\n",
    "\n",
    "        pos: o quão positiva é aquele frase/documento;\n",
    "\n",
    "        neu: o quão neutra é a frase/documento;\n",
    "\n",
    "        neg: o quanto é negativa;\n",
    "\n",
    "compound: é a métrica usada para indicar a conclusão final a respeito da frase como um todo. É calculada somando as pontuações de valência de cada palavra no léxico, o que gera um número entre -1 (muito negativo) e +1 (muito positivo). \n",
    "\n",
    "        Se for compound >= 0.05 -> Positivo\n",
    "\n",
    "        Se for compound <= -0.05 -> Negativo\n",
    "\n",
    "        Se for compound entre -0.04 e 0.04 -> Neutro\n",
    "\n",
    "O compound é a métrica mais importante quando você apenas quer saber se aquela frase é positiva ou negativa, porque seu valor pode ser convertido nessas respectivas categorias e é exatamente isso que vamos aprender a fazer aqui!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Andre_Rodrigues\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Análise completa com valores de sentimento pos, neg, neu e compound\n",
    "# Retorna um dicionário com os valores de sentimento neg, pos, neu e compound da frase passada\n",
    "def vader_complete_sentiment_analyse(text):\n",
    "    sentiment = SentimentIntensityAnalyzer().polarity_scores(text)\n",
    "    return sentiment\n",
    "\n",
    "# Análise simples que retorna pos, neg ou neu de acordo com o valor de compound\n",
    "def vader_get_sentiment(text):\n",
    "    sentiment = vader_complete_sentiment_analyse(text)\n",
    "    if sentiment['compound'] >= 0.05:\n",
    "        return 'Positive'\n",
    "    elif sentiment['compound'] <= -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Análise de sentimento dos DF com o modelo VADER\n",
    "def vader_df_sentiment_analyse(df):\n",
    "    # cria copia do dataframe para não alterar o original\n",
    "    df_copy = df.copy()\n",
    "    # Sentiment analysis\n",
    "    df_copy['Vader_Predict'] = df_copy.Text.apply(vader_get_sentiment)\n",
    "    # check accuracy\n",
    "    df_copy['Accuracy'] = accuracy_score(df_copy.Sentiment.values, df_copy.Vader_Predict.values)\n",
    "\n",
    "    return df_copy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_vader = vader_df_sentiment_analyse(df_train)\n",
    "df_test_vader = vader_df_sentiment_analyse(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Resultado Treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparação das quantidades obtidas com o dataset de treino x teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantidade de valores positivos e negativos reais no dataset:\n",
      "Positive    619\n",
      "Negative    595\n",
      "Name: Sentiment, dtype: int64\n",
      "\n",
      "Quantidade de valores positivos e negativos encontrados pelo modelo:\n",
      "Positive    946\n",
      "Negative    190\n",
      "Neutral      78\n",
      "Name: Vader_Predict, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Train - Visão geral sobre os sentimentos\n",
    "print(\"\\nQuantidade de valores positivos e negativos reais no dataset:\")\n",
    "print(df_train_vader.Sentiment.value_counts())\n",
    "\n",
    "print(\"\\nQuantidade de valores positivos e negativos encontrados pelo modelo:\")\n",
    "print(df_train_vader.Vader_Predict.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Vader_Predict</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200</td>\n",
       "      <td>B0028C44Z0</td>\n",
       "      <td>A1WTXY4MW3YDF2</td>\n",
       "      <td>Gordon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1344729600</td>\n",
       "      <td>These mints are awesome!</td>\n",
       "      <td>huge suppli im still work plenti spare much ef...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.607908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>560</td>\n",
       "      <td>B000G6RYNE</td>\n",
       "      <td>A10RJEQN64ATXU</td>\n",
       "      <td>Paul Rodney Williams \"Higher Lifestyle\"</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1188777600</td>\n",
       "      <td>delicious</td>\n",
       "      <td>love kettl brand sea salt vinegar chip sinc fi...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.607908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>B001EO5QW8</td>\n",
       "      <td>AQLL2R1PPR46X</td>\n",
       "      <td>grumpyrainbow</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1192752000</td>\n",
       "      <td>good</td>\n",
       "      <td>good oatmeal like appl cinnamon best though wo...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.607908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>552</td>\n",
       "      <td>B000G6RYNE</td>\n",
       "      <td>A2B5OI74EHGVH1</td>\n",
       "      <td>Jane \"jdeaton2\"</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1273017600</td>\n",
       "      <td>dripping in oil</td>\n",
       "      <td>purchas low salt inde low salt howev mani mani...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.607908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>2467</td>\n",
       "      <td>B002JX7GVM</td>\n",
       "      <td>AN9E7KAWWF95Q</td>\n",
       "      <td>ChristineThomson</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1348963200</td>\n",
       "      <td>Terrible flavor</td>\n",
       "      <td>almost gag first tast use coconut base product...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.607908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id   ProductId          UserId  \\\n",
       "199    200  B0028C44Z0  A1WTXY4MW3YDF2   \n",
       "559    560  B000G6RYNE  A10RJEQN64ATXU   \n",
       "46      47  B001EO5QW8   AQLL2R1PPR46X   \n",
       "551    552  B000G6RYNE  A2B5OI74EHGVH1   \n",
       "2466  2467  B002JX7GVM   AN9E7KAWWF95Q   \n",
       "\n",
       "                                  ProfileName  HelpfulnessNumerator  \\\n",
       "199                                    Gordon                     0   \n",
       "559   Paul Rodney Williams \"Higher Lifestyle\"                     3   \n",
       "46                              grumpyrainbow                     0   \n",
       "551                           Jane \"jdeaton2\"                     3   \n",
       "2466                         ChristineThomson                     0   \n",
       "\n",
       "      HelpfulnessDenominator  Score        Time                   Summary  \\\n",
       "199                        0      5  1344729600  These mints are awesome!   \n",
       "559                        3      5  1188777600                 delicious   \n",
       "46                         0      5  1192752000                      good   \n",
       "551                        8      1  1273017600           dripping in oil   \n",
       "2466                       0      2  1348963200           Terrible flavor   \n",
       "\n",
       "                                                   Text Sentiment  \\\n",
       "199   huge suppli im still work plenti spare much ef...  Positive   \n",
       "559   love kettl brand sea salt vinegar chip sinc fi...  Positive   \n",
       "46    good oatmeal like appl cinnamon best though wo...  Positive   \n",
       "551   purchas low salt inde low salt howev mani mani...  Negative   \n",
       "2466  almost gag first tast use coconut base product...  Negative   \n",
       "\n",
       "     Vader_Predict  Accuracy  \n",
       "199       Positive  0.607908  \n",
       "559       Positive  0.607908  \n",
       "46        Positive  0.607908  \n",
       "551       Negative  0.607908  \n",
       "2466      Negative  0.607908  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_vader.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Resultado Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantidade de valores positivos e negativos reais no dataset:\n",
      "Positive    619\n",
      "Negative    595\n",
      "Name: Sentiment, dtype: int64\n",
      "\n",
      "Quantidade de valores positivos e negativos encontrados pelo modelo:\n",
      "Positive    946\n",
      "Negative    190\n",
      "Neutral      78\n",
      "Name: Vader_Predict, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Train - Visão geral sobre os sentimentos\n",
    "print(\"\\nQuantidade de valores positivos e negativos reais no dataset:\")\n",
    "print(df_train_vader.Sentiment.value_counts())\n",
    "\n",
    "print(\"\\nQuantidade de valores positivos e negativos encontrados pelo modelo:\")\n",
    "print(df_train_vader.Vader_Predict.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Vader_Predict</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>134</td>\n",
       "      <td>B003OB0IB8</td>\n",
       "      <td>AOTEC8KEH8JGN</td>\n",
       "      <td>Seth S Moyers</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1334880000</td>\n",
       "      <td>Great value and convenient ramen</td>\n",
       "      <td>got sale rough 25 cent per cup half price loca...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.546053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>278</td>\n",
       "      <td>B001D07IPG</td>\n",
       "      <td>A3QN14A5DGUA0U</td>\n",
       "      <td>J. Kraayenbrink</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1343692800</td>\n",
       "      <td>Excellent for G/F</td>\n",
       "      <td>pleas ignor onestar comment check bag main ing...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.546053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>1521</td>\n",
       "      <td>B001LQNX8S</td>\n",
       "      <td>A2QA5W84LGMG8L</td>\n",
       "      <td>Dee</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1342742400</td>\n",
       "      <td>These are absolutely revolting</td>\n",
       "      <td>flavor pod horrid order senseo stock long need...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.546053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>2952</td>\n",
       "      <td>B000H280KS</td>\n",
       "      <td>AJITVA02GIXPO</td>\n",
       "      <td>Gretchen</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1173312000</td>\n",
       "      <td>Looks better than it tasted, I'm told</td>\n",
       "      <td>sent gift found later mani item stale love tho...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.546053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>759</td>\n",
       "      <td>B0035YE9CS</td>\n",
       "      <td>AGXFRN1RZKI4J</td>\n",
       "      <td>Earl Hudson</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1321228800</td>\n",
       "      <td>Outstanding Product!</td>\n",
       "      <td>saw made interest processdecid give tri realli...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.546053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id   ProductId          UserId      ProfileName  HelpfulnessNumerator  \\\n",
       "133    134  B003OB0IB8   AOTEC8KEH8JGN    Seth S Moyers                     0   \n",
       "277    278  B001D07IPG  A3QN14A5DGUA0U  J. Kraayenbrink                     0   \n",
       "1520  1521  B001LQNX8S  A2QA5W84LGMG8L              Dee                     0   \n",
       "2951  2952  B000H280KS   AJITVA02GIXPO         Gretchen                     0   \n",
       "758    759  B0035YE9CS   AGXFRN1RZKI4J      Earl Hudson                     0   \n",
       "\n",
       "      HelpfulnessDenominator  Score        Time  \\\n",
       "133                        0      5  1334880000   \n",
       "277                        0      5  1343692800   \n",
       "1520                       0      1  1342742400   \n",
       "2951                       0      2  1173312000   \n",
       "758                        1      5  1321228800   \n",
       "\n",
       "                                    Summary  \\\n",
       "133        Great value and convenient ramen   \n",
       "277                       Excellent for G/F   \n",
       "1520         These are absolutely revolting   \n",
       "2951  Looks better than it tasted, I'm told   \n",
       "758                    Outstanding Product!   \n",
       "\n",
       "                                                   Text Sentiment  \\\n",
       "133   got sale rough 25 cent per cup half price loca...  Positive   \n",
       "277   pleas ignor onestar comment check bag main ing...  Positive   \n",
       "1520  flavor pod horrid order senseo stock long need...  Negative   \n",
       "2951  sent gift found later mani item stale love tho...  Negative   \n",
       "758   saw made interest processdecid give tri realli...  Positive   \n",
       "\n",
       "     Vader_Predict  Accuracy  \n",
       "133       Positive  0.546053  \n",
       "277       Positive  0.546053  \n",
       "1520      Negative  0.546053  \n",
       "2951      Positive  0.546053  \n",
       "758       Positive  0.546053  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_vader.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regressão Logística model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É um modelo probabilístico de predição que busca prever um valor binário de 0 ou 1, e que é mais maleável e consegue ser utilizado em casos complexos de classificação. Na fórmula deste método, não são considerados outliers, tendo em vista que são apenas considerados dados próximos a uma reta que divide os dados de acordo com os atributos especificados. Assim como o algoritmo Perceptron, é um algoritmo que exige bastante treinamento e que apenas consegue encontrar um separador linear para os dados se estes forem linearmente separáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def logistic_regression_sentiment_analysis(df, iteractions=1000):\n",
    "    # generate BOW matrix\n",
    "    bow_matrix = generate_bow_matrix(df.Text)\n",
    "    # generate BOW frequency\n",
    "    bow_freq = generate_bow_freq(df.Text)\n",
    "    # generate BOW frequency dataframe\n",
    "    bow_freq_df = pd.DataFrame(bow_freq)\n",
    "    bow_freq_df.columns=[\"Palavra\", \"Frequência\"]\n",
    "    \n",
    "    # Logistic Regression\n",
    "    lr= LogisticRegression(max_iter=iteractions)\n",
    "    lr.fit(bow_matrix, df.Sentiment)\n",
    "\n",
    "    # copy dataframe para não alterar o original\n",
    "    df_copy = df.copy()\n",
    "    # predict\n",
    "    df_copy['Logistic_Predict'] = lr.predict(bow_matrix)\n",
    "    # check accuracy\n",
    "    df_copy['Accuracy'] = accuracy_score(df_copy.Sentiment.values, df_copy.Logistic_Predict.values)\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_lr = logistic_regression_sentiment_analysis(df_train)\n",
    "df_test_lr = logistic_regression_sentiment_analysis(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Resultado Treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparação das quantidades obtidas com o dataset de treino x teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantidade de valores positivos e negativos reais no dataset:\n",
      "Positive    619\n",
      "Negative    595\n",
      "Name: Sentiment, dtype: int64\n",
      "\n",
      "Quantidade de valores positivos e negativos encontrados pelo modelo:\n",
      "Positive    623\n",
      "Negative    591\n",
      "Name: Logistic_Predict, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Train - Visão geral sobre os sentimentos\n",
    "print(\"\\nQuantidade de valores positivos e negativos reais no dataset:\")\n",
    "print(df_train_lr.Sentiment.value_counts())\n",
    "\n",
    "print(\"\\nQuantidade de valores positivos e negativos encontrados pelo modelo:\")\n",
    "print(df_train_lr.Logistic_Predict.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Vader_Predict</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200</td>\n",
       "      <td>B0028C44Z0</td>\n",
       "      <td>A1WTXY4MW3YDF2</td>\n",
       "      <td>Gordon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1344729600</td>\n",
       "      <td>These mints are awesome!</td>\n",
       "      <td>huge suppli im still work plenti spare much ef...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.607908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>560</td>\n",
       "      <td>B000G6RYNE</td>\n",
       "      <td>A10RJEQN64ATXU</td>\n",
       "      <td>Paul Rodney Williams \"Higher Lifestyle\"</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1188777600</td>\n",
       "      <td>delicious</td>\n",
       "      <td>love kettl brand sea salt vinegar chip sinc fi...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.607908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>B001EO5QW8</td>\n",
       "      <td>AQLL2R1PPR46X</td>\n",
       "      <td>grumpyrainbow</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1192752000</td>\n",
       "      <td>good</td>\n",
       "      <td>good oatmeal like appl cinnamon best though wo...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.607908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>552</td>\n",
       "      <td>B000G6RYNE</td>\n",
       "      <td>A2B5OI74EHGVH1</td>\n",
       "      <td>Jane \"jdeaton2\"</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1273017600</td>\n",
       "      <td>dripping in oil</td>\n",
       "      <td>purchas low salt inde low salt howev mani mani...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.607908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>2467</td>\n",
       "      <td>B002JX7GVM</td>\n",
       "      <td>AN9E7KAWWF95Q</td>\n",
       "      <td>ChristineThomson</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1348963200</td>\n",
       "      <td>Terrible flavor</td>\n",
       "      <td>almost gag first tast use coconut base product...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.607908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id   ProductId          UserId  \\\n",
       "199    200  B0028C44Z0  A1WTXY4MW3YDF2   \n",
       "559    560  B000G6RYNE  A10RJEQN64ATXU   \n",
       "46      47  B001EO5QW8   AQLL2R1PPR46X   \n",
       "551    552  B000G6RYNE  A2B5OI74EHGVH1   \n",
       "2466  2467  B002JX7GVM   AN9E7KAWWF95Q   \n",
       "\n",
       "                                  ProfileName  HelpfulnessNumerator  \\\n",
       "199                                    Gordon                     0   \n",
       "559   Paul Rodney Williams \"Higher Lifestyle\"                     3   \n",
       "46                              grumpyrainbow                     0   \n",
       "551                           Jane \"jdeaton2\"                     3   \n",
       "2466                         ChristineThomson                     0   \n",
       "\n",
       "      HelpfulnessDenominator  Score        Time                   Summary  \\\n",
       "199                        0      5  1344729600  These mints are awesome!   \n",
       "559                        3      5  1188777600                 delicious   \n",
       "46                         0      5  1192752000                      good   \n",
       "551                        8      1  1273017600           dripping in oil   \n",
       "2466                       0      2  1348963200           Terrible flavor   \n",
       "\n",
       "                                                   Text Sentiment  \\\n",
       "199   huge suppli im still work plenti spare much ef...  Positive   \n",
       "559   love kettl brand sea salt vinegar chip sinc fi...  Positive   \n",
       "46    good oatmeal like appl cinnamon best though wo...  Positive   \n",
       "551   purchas low salt inde low salt howev mani mani...  Negative   \n",
       "2466  almost gag first tast use coconut base product...  Negative   \n",
       "\n",
       "     Vader_Predict  Accuracy  \n",
       "199       Positive  0.607908  \n",
       "559       Positive  0.607908  \n",
       "46        Positive  0.607908  \n",
       "551       Negative  0.607908  \n",
       "2466      Negative  0.607908  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_vader.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Resultado Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Logistic_Predict</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>134</td>\n",
       "      <td>B003OB0IB8</td>\n",
       "      <td>AOTEC8KEH8JGN</td>\n",
       "      <td>Seth S Moyers</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1334880000</td>\n",
       "      <td>Great value and convenient ramen</td>\n",
       "      <td>got sale rough 25 cent per cup half price loca...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>278</td>\n",
       "      <td>B001D07IPG</td>\n",
       "      <td>A3QN14A5DGUA0U</td>\n",
       "      <td>J. Kraayenbrink</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1343692800</td>\n",
       "      <td>Excellent for G/F</td>\n",
       "      <td>pleas ignor onestar comment check bag main ing...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>1521</td>\n",
       "      <td>B001LQNX8S</td>\n",
       "      <td>A2QA5W84LGMG8L</td>\n",
       "      <td>Dee</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1342742400</td>\n",
       "      <td>These are absolutely revolting</td>\n",
       "      <td>flavor pod horrid order senseo stock long need...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>2952</td>\n",
       "      <td>B000H280KS</td>\n",
       "      <td>AJITVA02GIXPO</td>\n",
       "      <td>Gretchen</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1173312000</td>\n",
       "      <td>Looks better than it tasted, I'm told</td>\n",
       "      <td>sent gift found later mani item stale love tho...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>759</td>\n",
       "      <td>B0035YE9CS</td>\n",
       "      <td>AGXFRN1RZKI4J</td>\n",
       "      <td>Earl Hudson</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1321228800</td>\n",
       "      <td>Outstanding Product!</td>\n",
       "      <td>saw made interest processdecid give tri realli...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id   ProductId          UserId      ProfileName  HelpfulnessNumerator  \\\n",
       "133    134  B003OB0IB8   AOTEC8KEH8JGN    Seth S Moyers                     0   \n",
       "277    278  B001D07IPG  A3QN14A5DGUA0U  J. Kraayenbrink                     0   \n",
       "1520  1521  B001LQNX8S  A2QA5W84LGMG8L              Dee                     0   \n",
       "2951  2952  B000H280KS   AJITVA02GIXPO         Gretchen                     0   \n",
       "758    759  B0035YE9CS   AGXFRN1RZKI4J      Earl Hudson                     0   \n",
       "\n",
       "      HelpfulnessDenominator  Score        Time  \\\n",
       "133                        0      5  1334880000   \n",
       "277                        0      5  1343692800   \n",
       "1520                       0      1  1342742400   \n",
       "2951                       0      2  1173312000   \n",
       "758                        1      5  1321228800   \n",
       "\n",
       "                                    Summary  \\\n",
       "133        Great value and convenient ramen   \n",
       "277                       Excellent for G/F   \n",
       "1520         These are absolutely revolting   \n",
       "2951  Looks better than it tasted, I'm told   \n",
       "758                    Outstanding Product!   \n",
       "\n",
       "                                                   Text Sentiment  \\\n",
       "133   got sale rough 25 cent per cup half price loca...  Positive   \n",
       "277   pleas ignor onestar comment check bag main ing...  Positive   \n",
       "1520  flavor pod horrid order senseo stock long need...  Negative   \n",
       "2951  sent gift found later mani item stale love tho...  Negative   \n",
       "758   saw made interest processdecid give tri realli...  Positive   \n",
       "\n",
       "     Logistic_Predict  Accuracy  \n",
       "133          Positive       1.0  \n",
       "277          Positive       1.0  \n",
       "1520         Negative       1.0  \n",
       "2951         Negative       1.0  \n",
       "758          Positive       1.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_lr.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "507b3d2bd6a2fcaac61041e0b692894325b154ca042b34fb821ed65ea08d8bdd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
